{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sb\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.dataset_large import ProtoPlanetaryDisks\n",
    "from src.ae_model import ConvLinTrans_AE\n",
    "\n",
    "main_path = os.path.dirname(os.getcwd())\n",
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_list(ID='zg3r4orb', device='cpu'):\n",
    "    \n",
    "    fname = glob.glob('%s/wandb/run-*-%s/model.pt' % \n",
    "                      (main_path, ID))[0]\n",
    "    \n",
    "    config_f = glob.glob('%s/wandb/run-*-%s/config.yaml' % \n",
    "                         (main_path, ID))[0]\n",
    "    with open(config_f, 'r') as f:\n",
    "        conf = yaml.safe_load(f)\n",
    "    conf = {k: v['value'] for k,v in conf.items() if 'wandb' not in k}\n",
    "    aux = re.findall('\\/run-(\\d+\\_\\d+?)-\\S+\\/', config_f)\n",
    "    conf['date'] = aux[0] if len(aux) != 0 else ''\n",
    "    del aux\n",
    "    conf['ID'] = ID\n",
    "    \n",
    "    print('Loading from... \\n', fname)\n",
    "    \n",
    "    model = ConvLinTrans_AE(latent_dim=conf['latent_dim'],\n",
    "                            img_dim=187,\n",
    "                            in_ch=1,\n",
    "                            kernel=conf['kernel_size'],\n",
    "                            n_conv_blocks=conf['conv_blocks'])\n",
    "        \n",
    "    state_dict = torch.load(fname, map_location=device)\n",
    "    if list(state_dict.keys())[0].split('.')[0] == 'module':\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "    else:\n",
    "        new_state_dict = state_dict\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    print('Is model in cuda? ', next(model.parameters()).is_cuda)\n",
    "    \n",
    "    return model, conf\n",
    "\n",
    "\n",
    "def evaluate_encoder(model, dataloader, conf, \n",
    "                     force=False, device='cpu'):\n",
    "    \n",
    "    fname_mu = '%s/wandb/run--%s/latent_space_mu.txt' % (main_path, conf['ID'])\n",
    "    fname_std = '%s/wandb/run--%s/latent_space_std.txt' % (main_path, conf['ID'])\n",
    "\n",
    "    if os.path.exists(fname_mu) & os.path.exists(fname_std) & ~force:\n",
    "        print('Loading from files...')\n",
    "        mu = np.loadtxt(fname_mu)\n",
    "        std = np.loadtxt(fname_std)\n",
    "    \n",
    "    else:\n",
    "        print('Evaluating Encoder...')\n",
    "        time_start = datetime.datetime.now()\n",
    "        \n",
    "        mu, logvar, xhat, labels = [], [], [], []\n",
    "        with tqdm_notebook(total=len(dataloader)) as pbar:\n",
    "            for i, (data, label, onehot, pp) in enumerate(dataloader):\n",
    "                data = data.to(device)\n",
    "                onehot = onehot.to(device)\n",
    "                pp = pp.to(device)\n",
    "                cc = torch.cat([onehot, pp], dim=1)\n",
    "                if params['label_dim'] > 0 and params['physics_dim'] > 0:\n",
    "                    mu_, logvar_ = model.encoder(data, label=onehot, phy=pp)\n",
    "                elif params['label_dim'] > 0 and params['physics_dim'] == 0:\n",
    "                    mu_, logvar_ = model.encoder(data, label=onehot)\n",
    "                elif params['label_dim'] == 0:\n",
    "                    mu_, logvar_ = model.encoder(data)\n",
    "                else:\n",
    "                    print('Check conditional dimension...')\n",
    "                mu.extend(mu_.data.cpu().numpy())\n",
    "                logvar.extend(logvar_.data.cpu().numpy())\n",
    "                labels.extend(label)\n",
    "                torch.cuda.empty_cache()\n",
    "                pbar.update()\n",
    "        mu = np.array(mu)\n",
    "        std = np.exp(0.5 * np.array(logvar))\n",
    "\n",
    "        #np.savetxt(fname_mu, mu)\n",
    "        #np.savetxt(fname_std, std)\n",
    "        #np.savetxt(fname_lbs, np.asarray(labels), fmt='%s')\n",
    "        elap_time = datetime.datetime.now() - time_start\n",
    "        print('Elapsed time  : %.2f s' % (elap_time.seconds))\n",
    "        print('##'*20)\n",
    "        \n",
    "    mu_df = pd.DataFrame(mu)\n",
    "    std_df = pd.DataFrame(std)\n",
    "        \n",
    "    mu_df['class'] = labels\n",
    "    std_df['class'] = labels\n",
    "    \n",
    "    return mu_df, std_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = '0ip71wfh'\n",
    "gpu = False\n",
    "rnd_seed = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('%s/wandb/run--%s/model.pt' % \n",
    "                      (main_path, ID)):\n",
    "    print('Downloading files from Weight & Biases')\n",
    "    \n",
    "    api = wandb.Api()\n",
    "    run = api.run('deep_ppd/PPD-AE/%s' % (ID))\n",
    "    run.file('model.pt').download(replace=True, \n",
    "                                  root='%s/wandb/run--%s/' % \n",
    "                                  (main_path, ID))\n",
    "    run.file('config.yaml').download(replace=True, \n",
    "                                     root='%s/wandb/run--%s/' % \n",
    "                                     (main_path, ID))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from... \n",
      " /home/jorgemarpa/Astro/PPDAE/wandb/run--0ip71wfh/model.pt\n",
      "Is model in cuda?  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'comment': 'overfitting',\n",
       " 'cond': 'F',\n",
       " 'conv_blocks': 4,\n",
       " 'data': 'PPD',\n",
       " 'dropout': 0.2,\n",
       " 'dry_run': False,\n",
       " 'early_stop': False,\n",
       " 'kernel_size': 3,\n",
       " 'latent_dim': 8,\n",
       " 'lr': 0.001,\n",
       " 'lr_sch': 'step',\n",
       " 'machine': 'exalearn',\n",
       " 'model_name': 'ConvLinTrans_AE',\n",
       " 'n_train_params': 4609667,\n",
       " 'num_epochs': 100,\n",
       " 'physics_dim': 0,\n",
       " 'rnd_seed': 13,\n",
       " 'date': '',\n",
       " 'ID': '0ip71wfh'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, config = load_model_list(ID=ID)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ProtoPlanetaryDisks(machine='exalearn', \n",
    "                              transform=False, img_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = dataset.get_dataloader(batch_size=128,\n",
    "                                                  shuffle=True,\n",
    "                                                  val_split=.2,\n",
    "                                                  random_seed=rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test_loader = DataLoader(dataset.imgs_test, \n",
    "                             batch_size=100, drop_last=False)\n",
    "par_test_loader = DataLoader(dataset.par_test, \n",
    "                             batch_size=100, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
